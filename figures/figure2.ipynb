{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2 - Performance summary of the spelling system during the copy-typing task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "from silent_spelling.utils import plotting_defaults, holm_bonferroni_correction, bootstrap_confidence_intervals\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject\n",
    "subject = 'bravo1'\n",
    "sig_thresh = 0.01\n",
    "pvalue_thresholds = [[1e-4, \"***\"], [0.001, \"**\"], [0.01, \"*\"], [1, \"ns\"]]\n",
    "\n",
    "fig_dir = 'saved_figures'\n",
    "load_from_RT = False\n",
    "save_to_excel = True\n",
    "\n",
    "# Name of the folder that contains result .pkl's\n",
    "result_folder_name = 'spelling_paper_signal_analyses'\n",
    "\n",
    "# Define the result file nums\n",
    "result_nums = {\n",
    "    'system_cer': 31,\n",
    "    'system_wer': 32,\n",
    "    'rates'     : 36,\n",
    "    'length'    : 52\n",
    "}\n",
    "\n",
    "excel_filepath = os.path.join(os.path.split(os.getcwd())[0], 'source_data', 'source_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_from_RT:\n",
    "    \n",
    "    # Custom software for file handling on Chang Lab systems\n",
    "    from RT.util import fileHandler, RTConfig\n",
    "    \n",
    "    # Load the data with RT and save in excel file\n",
    "    ## WER\n",
    "    result_path = fileHandler.getSubResultFilePath(\n",
    "        sub_dir_key='analysis',\n",
    "        result_label=result_folder_name,\n",
    "        sub_result_num=result_nums['system_wer']\n",
    "    )\n",
    "    system_wer = pd.read_hdf(result_path)\n",
    "    \n",
    "    ## CER\n",
    "    result_path = fileHandler.getSubResultFilePath(\n",
    "        sub_dir_key='analysis',\n",
    "        result_label=result_folder_name,\n",
    "        sub_result_num=result_nums['system_cer']\n",
    "    )\n",
    "    system_cer = pd.read_hdf(result_path)\n",
    "    \n",
    "    ## WPM and CPM\n",
    "    result_path = fileHandler.getSubResultFilePath(\n",
    "        sub_dir_key='analysis',\n",
    "        result_label=result_folder_name,\n",
    "        sub_result_num=result_nums['rates']\n",
    "    )\n",
    "    rates = pd.read_hdf(result_path)\n",
    "    \n",
    "    ## Sentence length\n",
    "    result_path = fileHandler.getSubResultFilePath(\n",
    "        sub_dir_key='analysis',\n",
    "        result_label=result_folder_name,\n",
    "        sub_result_num=result_nums['length']\n",
    "    )\n",
    "    lens = pd.read_hdf(result_path)\n",
    "    \n",
    "    if save_to_excel:\n",
    "        \n",
    "        if os.path.exists(excel_filepath):\n",
    "            mode = 'a'\n",
    "        else:\n",
    "            mode = 'w'\n",
    "        \n",
    "        with pd.ExcelWriter(excel_filepath, mode=mode) as writer:  \n",
    "            system_cer.to_excel(writer, sheet_name='Fig 2A', index=False)\n",
    "            system_wer.to_excel(writer, sheet_name='Fig 2B', index=False)\n",
    "            rates.to_excel(writer, sheet_name='Fig 2CD', index=False)\n",
    "            lens.to_excel(writer, sheet_name='Fig 2E', index=False)\n",
    "\n",
    "else:\n",
    "    system_cer = pd.read_excel(excel_filepath, sheet_name='Fig 2A', engine='openpyxl')\n",
    "    system_wer = pd.read_excel(excel_filepath, sheet_name='Fig 2B', engine='openpyxl')\n",
    "    rates = pd.read_excel(excel_filepath, sheet_name='Fig 2CD', engine='openpyxl')\n",
    "    lens = pd.read_excel(excel_filepath, sheet_name='Fig 2E', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablations - WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_wer['Word Error Rate'] = system_wer['Word Error Rate'].values * 100\n",
    "    \n",
    "system_wer_pvals_float = {}\n",
    "system_wer_stats_float = {}\n",
    "for c1, c2 in itertools.combinations(system_wer['Paradigm'].unique(), 2):\n",
    "    key = f'{c1}&{c2}'\n",
    "    group1 = system_wer.loc[system_wer['Paradigm'] == c1]['Word Error Rate'].values\n",
    "    group2 = system_wer.loc[system_wer['Paradigm'] == c2]['Word Error Rate'].values\n",
    "    system_wer_stats_float[key], system_wer_pvals_float[key] = stats.ranksums(group1, group2)\n",
    "    \n",
    "system_wer_pvals_float_corrected = holm_bonferroni_correction(system_wer_pvals_float)\n",
    "\n",
    "system_wer_pvals, system_wer_box_pairs = [], []\n",
    "wer_stats_df = {key: [] for key in ['Statistical comparison \\tnote{1}', '$\\mid$ \\textit{z}-value $\\mid$', '\\textit{P}-value \\\\ & & (corrected\\tnote{2}  )']}\n",
    "for key, val in system_wer_pvals_float_corrected.items():\n",
    "    c1, c2 = key.split('&')\n",
    "    \n",
    "    if val > sig_thresh:\n",
    "        continue\n",
    "        \n",
    "    wer_stats_df['Statistical comparison \\tnote{1}'].append(f'{c1} vs. {c2}')\n",
    "    wer_stats_df['$\\mid$ \\textit{z}-value $\\mid$'].append('{:0.2f}'.format(abs(system_wer_stats_float[key])))\n",
    "    wer_stats_df['\\textit{P}-value \\\\ & & (corrected\\tnote{2}  )'].append('\\num{{{:0.3g}}}'.format(val))\n",
    "    \n",
    "    \n",
    "    system_wer_box_pairs.append((c1, c2))\n",
    "    system_wer_pvals.append(val)\n",
    "    \n",
    "wer_stats_df = pd.DataFrame(data=wer_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_wer_stats_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_wer_pvals_float_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para in system_wer['Paradigm'].unique():\n",
    "    cur_wer = system_wer.loc[system_wer['Paradigm'] == para]['Word Error Rate'].values\n",
    "    print(para, np.median(cur_wer), bootstrap_confidence_intervals(cur_wer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_wer.Paradigm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablations - CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_cer['Character Error Rate'] = system_cer['Character Error Rate'].values * 100\n",
    "\n",
    "system_cer_pvals_float, system_cer_stats_float = {}, {}\n",
    "for c1, c2 in itertools.combinations(system_cer['Paradigm'].unique(), 2):\n",
    "    key = f'{c1}&{c2}'\n",
    "    group1 = system_cer.loc[system_cer['Paradigm'] == c1]['Character Error Rate'].values\n",
    "    group2 = system_cer.loc[system_cer['Paradigm'] == c2]['Character Error Rate'].values\n",
    "    system_cer_stats_float[key], system_cer_pvals_float[key] = stats.ranksums(group1, group2)\n",
    "    \n",
    "system_cer_pvals_float_corrected = holm_bonferroni_correction(system_cer_pvals_float)\n",
    "\n",
    "system_cer_pvals, system_cer_box_pairs = [], []\n",
    "cer_stats_df = {key: [] for key in ['Statistical comparison \\tnote{1}', '$\\mid$ \\textit{z}-value $\\mid$', '\\textit{P}-value \\\\ & & (corrected\\tnote{2}  )']}\n",
    "for key, val in system_cer_pvals_float_corrected.items():\n",
    "    c1, c2 = key.split('&')\n",
    "    \n",
    "    if val > sig_thresh:\n",
    "        continue\n",
    "        \n",
    "    cer_stats_df['Statistical comparison \\tnote{1}'].append(f'{c1} vs. {c2}')\n",
    "    cer_stats_df['$\\mid$ \\textit{z}-value $\\mid$'].append('{:0.2f}'.format(abs(system_cer_stats_float[key])))\n",
    "    cer_stats_df['\\textit{P}-value \\\\ & & (corrected\\tnote{2}  )'].append('\\num{{{:0.3g}}}'.format(val))\n",
    "    \n",
    "    system_cer_box_pairs.append((c1, c2))\n",
    "    system_cer_pvals.append(val)\n",
    "    \n",
    "cer_stats_df = pd.DataFrame(data=cer_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_cer_stats_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_cer_pvals_float_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para in system_cer['Paradigm'].unique():\n",
    "    cur_cer = system_cer.loc[system_cer['Paradigm'] == para]['Character Error Rate'].values\n",
    "    print(para, np.median(cur_cer), bootstrap_confidence_intervals(cur_cer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_cer.Paradigm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPM and WPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(rates.CPM.values), np.max(rates.CPM.values), bootstrap_confidence_intervals(rates.CPM.values))\n",
    "print(np.median(rates.WPM.values), np.max(rates.WPM.values), bootstrap_confidence_intervals(rates.WPM.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoded sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens['off'] = lens['length pred'].values - lens['length real'].values\n",
    "\n",
    "lengths, length_counts = np.unique(lens['off'].values, return_counts=True)\n",
    "length_percents = 100 * (length_counts / lens.shape[0])\n",
    "length_df = pd.DataFrame({'lengths': lengths, 'percent': length_percents, 'count': length_counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = {\n",
    "    'Chance': 'Chance',\n",
    "    'Only Neural Decoding': 'Only\\nneural\\ndecoding',\n",
    "    '+ Vocab. Constraints': '+Vocab.\\nconstr.',\n",
    "    '+ LM (Realtime results)': '+LM\\n(Real-time\\nresults)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth = 1\n",
    "annot_linewidth = 1\n",
    "plotting_defaults(font='Arial', fontsize=7, linewidth=linewidth)\n",
    "panel_label_fontsize = 7\n",
    "boxplot_kwargs = {'fliersize': 2, 'width': 0.5}\n",
    "mm = 1 / 25.4\n",
    "mm_figsize = [mm*180, mm*110]\n",
    "\n",
    "# orig_figsize = np.array([11, 11])\n",
    "fig = plt.figure(figsize=mm_figsize)\n",
    "gs = mpl.gridspec.GridSpec(2, 12, figure=fig, height_ratios=[1.3, 1])\n",
    "axs = {}\n",
    "\n",
    "colors = sns.color_palette('Set2')\n",
    "\n",
    "system_paradigms = system_cer.Paradigm.unique()\n",
    "system_paradigm_labels = [label.replace('+ ', '+').replace(' ', '\\n').replace('Realtime', 'Real-time') for label in system_paradigms]\n",
    "\n",
    "stripplot_kwargs = {\n",
    "    'color': 'k',\n",
    "    'alpha': 0.6,\n",
    "    's': 3\n",
    "}\n",
    "\n",
    "##### ----- System CER\n",
    "axs['system_cer'] = fig.add_subplot(gs[0, :4])\n",
    "axs['system_cer'] = sns.boxplot(data=system_cer, x='Paradigm', y='Character Error Rate',\n",
    "                                order=exp_names.keys(), ax=axs['system_cer'], palette='Set2', **boxplot_kwargs)\n",
    "# axs['system_cer'] = sns.stripplot(data=system_cer, x='Paradigm', y='Character Error Rate',\n",
    "#                                 order=exp_names.keys(), ax=axs['system_cer'], palette='Set2', \n",
    "#                                  edgecolor='black', linewidth=1.3)\n",
    "axs['system_cer'].axes.set(xticklabels=exp_names.values(), xlabel='', ylim=(None, 100))\n",
    "axs['system_cer'].axes.set_ylabel('Character error rate (%)', labelpad=-2)\n",
    "add_stat_annotation(axs['system_cer'], data=system_cer, x='Paradigm', y='Character Error Rate',\n",
    "                    order=exp_names.keys(), box_pairs=system_cer_box_pairs, perform_stat_test=False, \n",
    "                    pvalues=system_cer_pvals, text_format='star', loc='outside', pvalue_thresholds=pvalue_thresholds,\n",
    "                    linewidth=annot_linewidth, text_offset=-3)\n",
    "\n",
    "\n",
    "##### ----- System WER\n",
    "axs['system_wer'] = fig.add_subplot(gs[0, 4:8])\n",
    "axs['system_wer'] = sns.boxplot(data=system_wer, x='Paradigm', y='Word Error Rate',\n",
    "                                order=exp_names.keys(), ax=axs['system_wer'], palette='Set2', **boxplot_kwargs)\n",
    "# axs['system_wer'] = sns.stripplot(data=system_wer, x='Paradigm', y='Word Error Rate',\n",
    "#                                 order=exp_names.keys(), ax=axs['system_wer'], palette='Set2', \n",
    "#                                  edgecolor='black', linewidth=1.3)\n",
    "axs['system_wer'].axes.set(xticklabels=exp_names.values(), xlabel='', ylim=(None, 140), yticks=np.arange(0, 160, 20))\n",
    "axs['system_wer'].axes.set_ylabel('Word error rate (%)', labelpad=0)\n",
    "add_stat_annotation(axs['system_wer'], data=system_wer, x='Paradigm', y='Word Error Rate',\n",
    "                    order=exp_names.keys(), box_pairs=system_wer_box_pairs, perform_stat_test=False, \n",
    "                    pvalues=system_wer_pvals, text_format='star', loc='outside', pvalue_thresholds=pvalue_thresholds,\n",
    "                   linewidth=annot_linewidth, text_offset=-3)\n",
    "\n",
    "\n",
    "##### ----- CPM\n",
    "axs['cpm'] = fig.add_subplot(gs[0, 8:10])\n",
    "axs['cpm'] = sns.boxplot(data=rates, x='blocks', y='CPM',\n",
    "                         ax=axs['cpm'], palette=[colors[3]], **boxplot_kwargs)\n",
    "axs['cpm'].axes.set(xlabel='Real-time\\nresults', xticks=[], ylim=(27, 31), yticks=range(27, 32))\n",
    "axs['cpm'].axes.set_ylabel('Characters per minute', labelpad=1)\n",
    "\n",
    "\n",
    "##### ----- WPM\n",
    "axs['wpm'] = fig.add_subplot(gs[0, 10:])\n",
    "axs['wpm'] = sns.boxplot(data=rates, x='blocks', y='WPM',\n",
    "                         ax=axs['wpm'], palette=[colors[3]], **boxplot_kwargs)\n",
    "axs['wpm'].axes.set(xlabel='Real-time\\nresults', xticks=[], ylim=(4, 9))\n",
    "axs['wpm'].axes.set_ylabel('Words per minute', labelpad=1)\n",
    "\n",
    "\n",
    "##### ----- Sentence length\n",
    "axs['length'] = fig.add_subplot(gs[1, :3])\n",
    "axs['length'] = sns.barplot(data=length_df, x='lengths', y='percent', color=colors[3], ax=axs['length'])\n",
    "axs['length'].axes.set(ylim=(0, 100), xlim=(-1, 5), xticks=range(5), xticklabels=range(-2, 3), xlabel='No. of excess\\ncharacters')\n",
    "axs['length'].axes.set_ylabel('Percent of trials', labelpad=1)\n",
    "\n",
    "\n",
    "#### ----- Figure panel labels\n",
    "axs['system_cer'].annotate('a', (-0.2, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['system_wer'].annotate('b', (-0.2, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['cpm'].annotate('c', (-0.2, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['wpm'].annotate('d', (-0.2, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['length'].annotate('e', (-0.2, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "# axs['system_cer'].annotate('f', (-0.2, -0.6), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_dpi = 300\n",
    "\n",
    "for ext in ['png', 'pdf']:\n",
    "    fig.savefig(os.path.join(fig_dir, f'figure2_realtime_decoding.{ext}'), \n",
    "                transparent=True, bbox_inches='tight', dpi=figure_dpi)\n",
    "    fig.savefig(os.path.join(fig_dir, f'figure2_realtime_decoding_white.{ext}'), \n",
    "                transparent=False, bbox_inches='tight', dpi=figure_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gentz",
   "language": "python",
   "name": "gentz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
