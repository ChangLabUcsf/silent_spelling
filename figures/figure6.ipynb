{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6 - The spelling approach can generalize to larger vocabularies and conversational settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statannot import add_stat_annotation\n",
    "import matplotlib.font_manager\n",
    "\n",
    "from silent_spelling.utils import plotting_defaults, holm_bonferroni_correction, bootstrap_confidence_intervals\n",
    "\n",
    "plotting_defaults(font='Arial', fontsize=16)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject\n",
    "subject = 'bravo1'\n",
    "sig_thresh = 0.01\n",
    "\n",
    "fig_dir = 'saved_figures'\n",
    "load_from_RT = False\n",
    "save_to_excel = True\n",
    "\n",
    "# Name of the folder that contains result .pkl's\n",
    "result_folder_name = 'spelling_paper_signal_analyses'\n",
    "\n",
    "# Define the result file nums\n",
    "result_nums = {\n",
    "    'convo': 33,\n",
    "    'vocab_cer': 34,\n",
    "    'vocab_wer': 35\n",
    "}\n",
    "\n",
    "# Proper utterance set names\n",
    "vocab_names = {\n",
    "    'alphabet1_1': 'English alphabet',\n",
    "    'alphabet1_2': 'NATO code words'\n",
    "}\n",
    "lm_names = {\n",
    "    'Google 9k': '9,170',\n",
    "    'Oxford 5k': '5,249',\n",
    "    'Oxford 3k': '3,303',\n",
    "    'AAC 1k': '1,152'\n",
    "}\n",
    "\n",
    "excel_filepath = os.path.join(os.path.split(os.getcwd())[0], 'source_data', 'source_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_from_RT:\n",
    "    \n",
    "    # Custom software for file handling on Chang Lab systems\n",
    "    from RT.util import fileHandler, RTConfig\n",
    "    \n",
    "    # Load the data with RT and save in excel file\n",
    "    ## WER\n",
    "    result_path = fileHandler.getSubResultFilePath(\n",
    "        sub_dir_key='analysis',\n",
    "        result_label=result_folder_name,\n",
    "        sub_result_num=result_nums['vocab_wer']\n",
    "    )\n",
    "    vocab_wer = pd.read_hdf(result_path)\n",
    "    \n",
    "    ## CER\n",
    "    result_path = fileHandler.getSubResultFilePath(\n",
    "        sub_dir_key='analysis',\n",
    "        result_label=result_folder_name,\n",
    "        sub_result_num=result_nums['vocab_cer']\n",
    "    )\n",
    "    vocab_cer = pd.read_hdf(result_path)\n",
    "    \n",
    "    ## Conversation data\n",
    "    result_path = fileHandler.getSubResultFilePath(\n",
    "        sub_dir_key='analysis',\n",
    "        result_label=result_folder_name,\n",
    "        sub_result_num=result_nums['convo']\n",
    "    )\n",
    "    convo_df = pd.read_hdf(result_path)\n",
    "    \n",
    "    if save_to_excel:\n",
    "        \n",
    "        if os.path.exists(excel_filepath):\n",
    "            mode = 'a'\n",
    "        else:\n",
    "            mode = 'w'\n",
    "        \n",
    "        with pd.ExcelWriter(excel_filepath, mode=mode) as writer:  \n",
    "            vocab_cer.to_excel(writer, sheet_name='Fig 6A', index=False)\n",
    "            vocab_wer.to_excel(writer, sheet_name='Fig 6B', index=False)\n",
    "            convo_df.to_excel(writer, sheet_name='Fig 6C', index=False)\n",
    "\n",
    "else:\n",
    "    vocab_cer = pd.read_excel(excel_filepath, sheet_name='Fig 6A', engine='openpyxl')\n",
    "    vocab_wer = pd.read_excel(excel_filepath, sheet_name='Fig 6B', engine='openpyxl')\n",
    "    convo_df = pd.read_excel(excel_filepath, sheet_name='Fig 6C', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_cer['Character Error Rate'] = vocab_cer['Character Error Rate'].values * 100\n",
    "\n",
    "vocab_cer_pvals_float = {}\n",
    "vocab_cer_stats_float = {}\n",
    "for c1, c2 in itertools.combinations(vocab_cer['Paradigm'].unique(), 2):\n",
    "    key = f'{c1}&{c2}'\n",
    "    group1 = vocab_cer.loc[vocab_cer['Paradigm'] == c1]['Character Error Rate'].values\n",
    "    group2 = vocab_cer.loc[vocab_cer['Paradigm'] == c2]['Character Error Rate'].values\n",
    "    vocab_cer_stats_float[key], vocab_cer_pvals_float[key] = stats.ranksums(group1, group2)\n",
    "    \n",
    "vocab_cer_pvals_float_corrected = holm_bonferroni_correction(vocab_cer_pvals_float)\n",
    "\n",
    "vocab_cer_pvals, vocab_cer_box_pairs = [], []\n",
    "for key, val in vocab_cer_pvals_float_corrected.items():\n",
    "    c1, c2 = key.split('&')\n",
    "    vocab_cer_box_pairs.append((c1, c2))\n",
    "    vocab_cer_pvals.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_cer_stats_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para in vocab_cer.Paradigm.unique():\n",
    "    cur_cer = vocab_cer.loc[vocab_cer.Paradigm == para]['Character Error Rate'].values\n",
    "    print(f'\\n{para}')\n",
    "    print(np.median(cur_cer))\n",
    "    print(bootstrap_confidence_intervals(cur_cer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_wer['Word Error Rate'] = vocab_wer['Word Error Rate'].values * 100\n",
    "\n",
    "vocab_wer_pvals_float = {}\n",
    "vocab_wer_stats_float = {}\n",
    "for c1, c2 in itertools.combinations(vocab_wer['Paradigm'].unique(), 2):\n",
    "    key = f'{c1}&{c2}'\n",
    "    group1 = vocab_wer.loc[vocab_wer['Paradigm'] == c1]['Word Error Rate'].values\n",
    "    group2 = vocab_wer.loc[vocab_wer['Paradigm'] == c2]['Word Error Rate'].values\n",
    "    vocab_wer_stats_float[key], vocab_wer_pvals_float[key] = stats.ranksums(group1, group2)\n",
    "    \n",
    "vocab_wer_pvals_float_corrected = holm_bonferroni_correction(vocab_wer_pvals_float)\n",
    "print(f'{len(vocab_wer_pvals_float.keys())}-way Holm-Bonferroni correction')\n",
    "\n",
    "vocab_wer_pvals, vocab_wer_box_pairs = [], []\n",
    "for key, val in vocab_wer_pvals_float_corrected.items():\n",
    "    c1, c2 = key.split('&')\n",
    "    vocab_wer_box_pairs.append((c1, c2))\n",
    "    vocab_wer_pvals.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para in vocab_wer.Paradigm.unique():\n",
    "    cur_wer = vocab_wer.loc[vocab_wer.Paradigm == para]['Word Error Rate'].values\n",
    "    print(f'\\n{para}')\n",
    "    print(np.median(cur_wer))\n",
    "    print(bootstrap_confidence_intervals(cur_wer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation CER & WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_df['Percent Error Rate'] = convo_df['Error Rate'].values * 100\n",
    "\n",
    "for para in convo_df['Metric Type'].unique():\n",
    "    cur_wer = convo_df.loc[convo_df['Metric Type'] == para]['Percent Error Rate'].values\n",
    "    print(f'\\n{para}')\n",
    "    print(np.median(cur_wer))\n",
    "    print(bootstrap_confidence_intervals(cur_wer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth = 1\n",
    "annot_linewidth = 1\n",
    "fontsize = 7\n",
    "plotting_defaults(font='Arial', fontsize=fontsize, linewidth=linewidth)\n",
    "panel_label_fontsize = 7\n",
    "boxplot_kwargs = {'fliersize': 3, 'width': 0.5}\n",
    "scatter_size = 3\n",
    "mm = 1 / 25.4\n",
    "mm_figsize = [mm*180, mm*50]\n",
    "\n",
    "fig = plt.figure(figsize=mm_figsize)\n",
    "gs = mpl.gridspec.GridSpec(1, 4, figure=fig, width_ratios=[2, 2, 1, 5])\n",
    "axs = {}\n",
    "\n",
    "vocab_paradigms = vocab_cer['Paradigm'].unique()\n",
    "\n",
    "order = np.flip(vocab_paradigms)\n",
    "xticklabels = [lm_names[key] for key in order]\n",
    "\n",
    "##### ----- Vocab CER\n",
    "axs['vocab_cer'] = fig.add_subplot(gs[0, 0])\n",
    "axs['vocab_cer'] = sns.boxplot(data=vocab_cer, x='Paradigm', y='Character Error Rate',\n",
    "                                order=order, ax=axs['vocab_cer'], palette='Set2', **boxplot_kwargs)\n",
    "axs['vocab_cer'].axes.set(xlabel='Vocabulary size (words)', ylim=(None, 50), yticks=range(0, 51, 10), ylabel='Character error rate (%)',\n",
    "                         xticklabels=xticklabels)\n",
    "axs['vocab_cer'].tick_params(axis='x', labelrotation=45)\n",
    "# add_stat_annotation(axs['vocab_cer'], data=vocab_cer, x='Paradigm', y='Character Error Rate',\n",
    "#                    box_pairs=vocab_cer_box_pairs, perform_stat_test=False, pvalues=vocab_cer_pvals,\n",
    "#                    text_format='star', loc='outside', order=vocab_paradigms)\n",
    "\n",
    "\n",
    "##### ----- Vocab WER\n",
    "axs['vocab_wer'] = fig.add_subplot(gs[0, 1])\n",
    "axs['vocab_wer'] = sns.boxplot(data=vocab_wer, x='Paradigm', y='Word Error Rate',\n",
    "                                order=order, ax=axs['vocab_wer'], palette='Set2', **boxplot_kwargs)\n",
    "axs['vocab_wer'].axes.set(xlabel='Vocabulary size (words)', ylim=(None, 70), yticks=range(0, 71, 10), ylabel='Word error rate (%)',\n",
    "                         xticklabels=xticklabels)\n",
    "axs['vocab_wer'].tick_params(axis='x', labelrotation=45)\n",
    "# add_stat_annotation(axs['vocab_wer'], data=vocab_wer, x='Paradigm', y='Word Error Rate',\n",
    "#                    box_pairs=vocab_wer_box_pairs, perform_stat_test=False, pvalues=vocab_wer_pvals,\n",
    "#                    text_format='star', loc='outside', order=vocab_paradigms)\n",
    "\n",
    "\n",
    "##### ----- Conversation CER & WER\n",
    "colors = sns.color_palette('Set2')[4:6]\n",
    "axs['convo'] = fig.add_subplot(gs[0, 2])\n",
    "axs['convo'] = sns.boxplot(data=convo_df, x='Metric Type', y='Percent Error Rate',\n",
    "                           order=['cer', 'wer'],showfliers=False, ax=axs['convo'], palette=colors, **boxplot_kwargs)\n",
    "axs['convo'] = sns.stripplot(data=convo_df, x='Metric Type', y='Percent Error Rate',\n",
    "                           order=['cer', 'wer'], ax=axs['convo'], palette=colors, \n",
    "                            edgecolor='black', linewidth=linewidth - 0.5, size=scatter_size)\n",
    "axs['convo'].axes.set(xlabel='', ylim=(None, 60), xticklabels=['Char.', 'Word'], ylabel='Error rate (%)')\n",
    "\n",
    "a = fig.add_subplot(gs[0, -1])\n",
    "a.axis('off')\n",
    "\n",
    "##### ----- Figure panel labels\n",
    "axs['vocab_cer'].annotate('a', (-0.25, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['vocab_wer'].annotate('b', (-0.25, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['convo'].annotate('c', (-0.25, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['convo'].annotate('d', (1.2, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_dpi = 300\n",
    "\n",
    "for ext in ['png', 'pdf']:\n",
    "    fig.savefig(os.path.join(fig_dir, f'figure6_vocab_convo.{ext}'), \n",
    "                transparent=True, bbox_inches='tight', dpi=figure_dpi)\n",
    "    fig.savefig(os.path.join(fig_dir, f'figure6_vocab_convo_white.{ext}'), \n",
    "                transparent=False, bbox_inches='tight', dpi=figure_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gentz",
   "language": "python",
   "name": "gentz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
