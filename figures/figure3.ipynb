{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3 - Characterization of high-gamma activity (HGA) and low-frequency signals (LFS) during silent-speech attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "from silent_spelling.plotting import plot_images_and_elecs\n",
    "from silent_spelling.utils import plotting_defaults, holm_bonferroni_correction, correlation_permutation, bootstrap_confidence_intervals\n",
    "\n",
    "plotting_defaults(font='Arial', fontsize=16)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject\n",
    "subject = 'bravo1'\n",
    "sr = 200\n",
    "sig_thresh = 0.01\n",
    "pvalue_thresholds = [[1e-4, \"***\"], [0.001, \"**\"], [0.01, \"*\"], [1, \"ns\"]]\n",
    "\n",
    "fig_dir = 'saved_figures'\n",
    "load_from_RT = False\n",
    "save_to_excel = True\n",
    "\n",
    "# Name of the folder that contains result .pkl's\n",
    "result_folder_name = 'spelling_paper_signal_analyses'\n",
    "\n",
    "# Define the result file nums\n",
    "result_nums = {\n",
    "    'raw_alone_salience': 80,\n",
    "    'hga_alone_salience': 78,\n",
    "    'rawhga_salience': 79,\n",
    "    'hga_raw_acc': 77,\n",
    "    'hga_raw_pr': 81,\n",
    "    'temporal_smoothing': 82\n",
    "}\n",
    "\n",
    "stats_nums = {\n",
    "    'salience_corr_permute': 86\n",
    "}\n",
    "\n",
    "# Proper utterance set names\n",
    "stim_set_names = {\n",
    "    'alphabet1_1': 'English alphabet',\n",
    "    'alphabet1_2': 'NATO codewords'\n",
    "}\n",
    "\n",
    "# Proper feature names\n",
    "all_feature_names = {\n",
    "    'hga': 'HGA',\n",
    "    'raw': 'LFS',\n",
    "    'hga + raw': 'HGA+LFS',\n",
    "    'hga_and_raw': 'HGA+LFS'\n",
    "}\n",
    "feature_names = {\n",
    "    'hga': 'HGA',\n",
    "    'raw': 'LFS',\n",
    "    'hga + raw': 'HGA+LFS'\n",
    "}\n",
    "second_feature_names = {\n",
    "    'HGA': 'HGA',\n",
    "    'LFS': 'LFS',\n",
    "    'HGA + LFS': 'HGA+LFS'\n",
    "}\n",
    "\n",
    "cwd = os.path.split(os.getcwd())[0]\n",
    "\n",
    "# Load brain image and electrode coordinates\n",
    "brain_img = plt.imread(f'recon/{subject}_brain_2D.png')\n",
    "elec_coords = np.load(f'recon/{subject}_elecmat_2D.npy')\n",
    "elec_layout = np.load(f'recon/{subject}_elec_layout.npy')\n",
    "\n",
    "paradigms = ['overt', 'mimed']\n",
    "\n",
    "with open(f'{cwd}/letter_codeword_label_mapping.pkl', 'rb') as f:\n",
    "    label_mapping = pickle.load(f)\n",
    "    \n",
    "letter_labels = list(label_mapping['alphabet1_1'].keys())\n",
    "\n",
    "excel_filepath = os.path.join(cwd, 'source_data', 'source_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_from_RT:\n",
    "    \n",
    "    # Custom software for file handling on Chang Lab systems\n",
    "    from RT.util import fileHandler, RTConfig\n",
    "    \n",
    "    # Saliences\n",
    "    saliences = {}\n",
    "    for sal_key in ['raw_alone_salience', 'hga_alone_salience', 'rawhga_salience']:\n",
    "        result_path = fileHandler.getSubResultFilePath(\n",
    "            sub_dir_key='analysis',\n",
    "            result_label=result_folder_name,\n",
    "            sub_result_num=result_nums[sal_key]\n",
    "        )\n",
    "        temp_sal = np.load(result_path)\n",
    "\n",
    "        # Find the cutoff for padding\n",
    "        cutoff = np.where(temp_sal[0, :, 0] == 0)[0][0]\n",
    "\n",
    "        # Take the L2 norm across time, then average by trial\n",
    "        saliences[sal_key] = np.mean(np.linalg.norm(temp_sal[:, :cutoff, :], 2, axis=1), axis=0)\n",
    "\n",
    "    ## HGA vs LFS accuracy\n",
    "    result_path = fileHandler.getSubResultFilePath(\n",
    "        sub_dir_key='analysis',\n",
    "        result_label=result_folder_name,\n",
    "        sub_result_num=result_nums['hga_raw_acc']\n",
    "    )\n",
    "    hga_raw_df = pd.read_hdf(result_path)\n",
    "    \n",
    "    ## Number of PCs for spatial and temporal variance\n",
    "    result_path = fileHandler.getSubResultFilePath(\n",
    "        sub_dir_key='analysis',\n",
    "        result_label=result_folder_name,\n",
    "        sub_result_num=result_nums['hga_raw_pr']\n",
    "    )\n",
    "    hga_raw_pr_df = pd.read_hdf(result_path)\n",
    "    \n",
    "    ## Temporal smoothing\n",
    "    result_path = fileHandler.getSubResultFilePath(\n",
    "        sub_dir_key='analysis',\n",
    "        result_label=result_folder_name,\n",
    "        sub_result_num=result_nums['temporal_smoothing']\n",
    "    )\n",
    "    temporal_smoothing = pd.read_hdf(result_path)\n",
    "                \n",
    "    if save_to_excel:\n",
    "        \n",
    "        if os.path.exists(excel_filepath):\n",
    "            mode = 'a'\n",
    "        else:\n",
    "            mode = 'w'\n",
    "        \n",
    "        with pd.ExcelWriter(excel_filepath, mode=mode) as writer:\n",
    "            \n",
    "            hga_raw_df.to_excel(writer, sheet_name='Fig 3A', index=False)\n",
    "            \n",
    "            for key, val in saliences.items():\n",
    "                pd.DataFrame(val).to_excel(writer, sheet_name=f'Fig 3B-E_{key}', index=False)\n",
    "            \n",
    "            hga_raw_pr_df.to_excel(writer, sheet_name='Fig 3FG', index=False)\n",
    "            temporal_smoothing.to_excel(writer, sheet_name='Fig 3H', index=False)\n",
    "\n",
    "else:\n",
    "    \n",
    "    saliences = {}\n",
    "    for key in ['raw_alone_salience', 'hga_alone_salience', 'rawhga_salience']:\n",
    "        saliences[key] = pd.read_excel(excel_filepath, sheet_name=f'Fig 3B-E_{key}', engine='openpyxl').values.squeeze()\n",
    "                \n",
    "    hga_raw_df = pd.read_excel(excel_filepath, sheet_name='Fig 3A', engine='openpyxl')\n",
    "    hga_raw_pr_df = pd.read_excel(excel_filepath, sheet_name='Fig 3FG', engine='openpyxl')\n",
    "    temporal_smoothing = pd.read_excel(excel_filepath, sheet_name='Fig 3H', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HGA vs raw vs HGA + raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saliences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_alone = saliences['raw_alone_salience'] / np.sum(saliences['raw_alone_salience'])\n",
    "hga_alone = saliences['hga_alone_salience'] / np.sum(saliences['hga_alone_salience'])\n",
    "raw_combo = saliences['rawhga_salience'][:128] / np.sum(saliences['rawhga_salience'][:128])\n",
    "hga_combo = saliences['rawhga_salience'][128:] / np.sum(saliences['rawhga_salience'][128:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 2000\n",
    "\n",
    "if load_from_RT:\n",
    "    \n",
    "    from RT.util import fileHandler, RTConfig\n",
    "    \n",
    "    if stats_nums['salience_corr_permute'] is not None:\n",
    "        stats_results_path = fileHandler.getSubResultFilePath(\n",
    "            sub_dir_key='analysis',\n",
    "            result_label=result_folder_name,\n",
    "            sub_result_num=stats_nums['salience_corr_permute'],\n",
    "            extension='.h5'\n",
    "        )\n",
    "        sal_corr_permute = pd.read_hdf(stats_results_path, key='df')\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        print('Computing correlations...')\n",
    "        \n",
    "        stats_results_path = fileHandler.getSubResultFilePath(\n",
    "            sub_dir_key='analysis',\n",
    "            result_label=result_folder_name,\n",
    "            next_file_sub_label='salience_corr_permute'\n",
    "        )\n",
    "\n",
    "        sal_corr_permute = {'feature': [], 'spearman_corr': [], 'pvalue': []}\n",
    "        \n",
    "        sal_corr_permute['feature'].append('hga_vs_hgaraw')\n",
    "        r, p = correlation_permutation(hga_alone, \n",
    "                                        hga_combo, \n",
    "                                        corr=stats.spearmanr, \n",
    "                                        n_permute=P)\n",
    "        sal_corr_permute['spearman_corr'].append(r)\n",
    "        sal_corr_permute['pvalue'].append(p)\n",
    "        \n",
    "        sal_corr_permute['feature'].append('raw_vs_hgaraw')\n",
    "        r, p = correlation_permutation(raw_alone, \n",
    "                                    raw_combo, \n",
    "                                    corr=stats.spearmanr, \n",
    "                                    n_permute=P)\n",
    "        sal_corr_permute['spearman_corr'].append(r)\n",
    "        sal_corr_permute['pvalue'].append(p)\n",
    "        \n",
    "        sal_corr_permute['feature'].append('hga_vs_raw')\n",
    "        r, p = correlation_permutation(hga_alone,\n",
    "                                     raw_alone, \n",
    "                                     corr=stats.spearmanr, \n",
    "                                     n_permute=P)\n",
    "        sal_corr_permute['spearman_corr'].append(r)\n",
    "        sal_corr_permute['pvalue'].append(p)\n",
    "        \n",
    "        sal_corr_permute = pd.DataFrame(data=sal_corr_permute)\n",
    "        sal_corr_permute.to_hdf(stats_results_path + '.h5', key='df', mode='w')  \n",
    "    \n",
    "    if save_to_excel:\n",
    "        \n",
    "        if os.path.exists(excel_filepath):\n",
    "            mode = 'a'\n",
    "        else:\n",
    "            mode = 'w'\n",
    "        \n",
    "        with pd.ExcelWriter(excel_filepath, mode=mode) as writer:\n",
    "            sal_corr_permute.to_excel(writer, sheet_name='Fig 3B-E_stats', index=False)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    sal_corr_permute = pd.read_excel(excel_filepath, sheet_name='Fig 3B-E_stats', engine='openpyxl')\n",
    "\n",
    "sal_corr_permute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgaraw_boxplot_dict = {}\n",
    "for feat in second_feature_names.keys():\n",
    "    hgaraw_boxplot_dict[feat] = hga_raw_df.loc[hga_raw_df['Features'] == feat]['Accuracy'].values\n",
    "\n",
    "hgaraw_stats_float, hgaraw_pvals_float = {}, {}\n",
    "for c1, c2 in itertools.combinations(second_feature_names.keys(), 2):\n",
    "    key = f'{c1}&{c2}'\n",
    "    hgaraw_stats_float[key], hgaraw_pvals_float[key] = stats.ranksums(hgaraw_boxplot_dict[c1], hgaraw_boxplot_dict[c2])\n",
    "\n",
    "hgaraw_pvals_float_corrected = holm_bonferroni_correction(hgaraw_pvals_float)\n",
    "\n",
    "hgaraw_pvals, hgaraw_box_pairs = [], []\n",
    "acc_stats_df = {key: [] for key in ['Statistical comparison \\tnote{1}', '$\\mid$ \\textit{z}-value $\\mid$', '\\textit{P}-value \\\\ & & (corrected\\tnote{2}  )']}\n",
    "for key, val in hgaraw_pvals_float_corrected.items():\n",
    "    c1, c2 = key.split('&')\n",
    "    hgaraw_box_pairs.append((c1, c2))\n",
    "    hgaraw_pvals.append(val)\n",
    "    \n",
    "    acc_stats_df['Statistical comparison \\tnote{1}'].append(f'{c1} vs. {c2}')\n",
    "    acc_stats_df['$\\mid$ \\textit{z}-value $\\mid$'].append('{:0.2f}'.format(abs(hgaraw_stats_float[key])))\n",
    "    acc_stats_df['\\textit{P}-value \\\\ & & (corrected\\tnote{2}  )'].append('\\num{{{:0.3g}}}'.format(val))\n",
    "    \n",
    "acc_stats_df = pd.DataFrame(data=acc_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgaraw_stats_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgaraw_pvals_float_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hga_raw_df.groupby(['Features']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_confidence_intervals(hga_raw_df.loc[hga_raw_df.Features == 'HGA + LFS'].Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No. PCs >80% variance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hga_raw_pr_dict = {'temporal': {}, 'spatial': {}}\n",
    "    \n",
    "for feat in feature_names.keys():\n",
    "    hga_raw_pr_dict['temporal'][feat] = hga_raw_pr_df.loc[hga_raw_pr_df['Condition'] == feat]['80% var PC, Temporal'].values\n",
    "    hga_raw_pr_dict['spatial'][feat] = hga_raw_pr_df.loc[hga_raw_pr_df['Condition'] == feat]['80% var PC, Spatial'].values\n",
    "    \n",
    "hga_raw_pr_pvals_float = {'temporal': {}, 'spatial': {}}\n",
    "hga_raw_pr_stats_float = {'temporal': {}, 'spatial': {}}\n",
    "for c1, c2 in itertools.combinations(feature_names.keys(), 2):\n",
    "    key = f'{c1}&{c2}'\n",
    "    hga_raw_pr_stats_float['temporal'][key], hga_raw_pr_pvals_float['temporal'][key] = stats.ranksums(hga_raw_pr_dict['temporal'][c1], hga_raw_pr_dict['temporal'][c2])\n",
    "    hga_raw_pr_stats_float['spatial'][key], hga_raw_pr_pvals_float['spatial'][key] = stats.ranksums(hga_raw_pr_dict['spatial'][c1], hga_raw_pr_dict['spatial'][c2])\n",
    "\n",
    "hgaraw_pr_box_pairs = {'temporal': [], 'spatial': []}\n",
    "hgaraw_pr_pvals = {'temporal': [], 'spatial': []}\n",
    "\n",
    "temp = {key: [] for key in ['Statistical comparison \\tnote{1}', '$\\mid$ \\textit{z}-value $\\mid$', '\\textit{P}-value \\\\ & & (corrected\\tnote{2}  )']}\n",
    "pr_stats = {'temporal': copy.deepcopy(temp), 'spatial': copy.deepcopy(temp)}\n",
    "\n",
    "for pr_type in hga_raw_pr_pvals_float.keys():\n",
    "    \n",
    "    corrected_pvals = holm_bonferroni_correction(hga_raw_pr_pvals_float[pr_type])\n",
    "    \n",
    "    for key, val in corrected_pvals.items():\n",
    "        \n",
    "        if val > sig_thresh:\n",
    "            continue\n",
    "        \n",
    "        c1, c2 = key.split('&')\n",
    "        hgaraw_pr_box_pairs[pr_type].append((c1, c2))\n",
    "        hgaraw_pr_pvals[pr_type].append(val)\n",
    "        \n",
    "        pr_stats[pr_type]['Statistical comparison \\tnote{1}'].append(f'{feature_names[c1]} vs. {feature_names[c2]}')\n",
    "        pr_stats[pr_type]['$\\mid$ \\textit{z}-value $\\mid$'].append('{:0.2f}'.format(abs(hga_raw_pr_stats_float[pr_type][key])))\n",
    "        pr_stats[pr_type]['\\textit{P}-value \\\\ & & (corrected\\tnote{2}  )'].append('\\num{{{:0.3g}}}'.format(val))\n",
    "        \n",
    "temp_stats_df = pd.DataFrame(data=pr_stats['temporal'])\n",
    "spatial_stats_df = pd.DataFrame(data=pr_stats['spatial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hga_raw_pr_df['80% var PC, Spatial'].max(), hga_raw_pr_df['80% var PC, Temporal'].max())\n",
    "print(hga_raw_pr_df['80% var PC, Spatial'].min(), hga_raw_pr_df['80% var PC, Temporal'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hga_raw_pr_stats_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_smoothing = temporal_smoothing.loc[temporal_smoothing['Temporal Smoothing'] != 1]\n",
    "\n",
    "# Convert to seconds\n",
    "temporal_smoothing['Temporal Smoothing (s)'] = temporal_smoothing['Temporal Smoothing'].values / sr\n",
    "\n",
    "temporal_smoothing['temporal_smoothing'] = temporal_smoothing['Temporal Smoothing (s)'].values\n",
    "temporal_smoothing['accuracy_fraction'] = temporal_smoothing['accuracy (% of original)'].values\n",
    "temporal_smoothing['feature_type'] = temporal_smoothing['Data Type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs Wilcoxon signed-rank tests\n",
    "data_types = set(temporal_smoothing['Data Type'])\n",
    "smoothings = sorted(set(temporal_smoothing['Temporal Smoothing (s)']))\n",
    "acc_fracs = {k: [] for k in data_types}\n",
    "\n",
    "for cur_smoothing in smoothings:\n",
    "    cur_df = temporal_smoothing[temporal_smoothing['Temporal Smoothing (s)'] == cur_smoothing]\n",
    "    cur_data = {k : cur_df[cur_df['Data Type'] == k]['accuracy_fraction'].values for k in data_types}\n",
    "    assert len(np.unique([len(v) for v in cur_data.values()])) == 1\n",
    "    for k, v in cur_data.items():\n",
    "        acc_fracs[k].extend(list(v))\n",
    "\n",
    "stats_results = [\n",
    "    {'key1' : k1, 'key2': k2, 'p': stats.wilcoxon(acc_fracs[k1], acc_fracs[k2])[1], 'stat': stats.wilcoxon(acc_fracs[k1], acc_fracs[k2])[0]}\n",
    "    for k1, k2 in itertools.combinations(data_types, 2)\n",
    "]\n",
    "corrected_p_vals = holm_bonferroni_correction(\n",
    "    {i: v['p'] for i, v in enumerate(stats_results)}\n",
    ")\n",
    "for k, cur_corrected_p in corrected_p_vals.items():\n",
    "    stats_results[k]['p_mc_corrected'] = cur_corrected_p\n",
    "results_df = pd.DataFrame(stats_results)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters: these are the same for all plots so we can just reuse them\n",
    "cbar_params = {\n",
    "    'plot_colorbar'        : False,\n",
    "    'colorbar_title'       : 'Color title',\n",
    "}\n",
    "elec_size_color_params = {\n",
    "    'color_params' : {'min': 0,  'max': 1.0,   'relative': True},\n",
    "    'size_params'  : {'min': 10, 'max': 30, 'relative': True, 'scale': 30},\n",
    "    'alpha_params' : {'min': 0.2, 'max': 1.0,  'relative': True, 'exponent': 0.5}\n",
    "}\n",
    "other_params = {\n",
    "    'show_fig': False,\n",
    "    'elec_size_color_params': elec_size_color_params\n",
    "}\n",
    "all_plot_params = {'elec_loc_file_path': 'bravo1_elecmat_2D.npy',\n",
    " 'all_image_params': {'file_name': 'bravo1_brain_2D.png',\n",
    "  'invert_y': True,\n",
    "  'alpha': 0.25},\n",
    " 'y_scale': -1.0,\n",
    " 'add_height': True,\n",
    " 'elec_plot_params': {'linewidths': 0.0, 'zorder': 100000.0},\n",
    " 'elec_size_color_params': {'color_spec': 'black',\n",
    "  'size_params': {'min': 100.0, 'max': 100.0, 'relative': False},\n",
    "  'alpha_params': {'min': 0.8, 'max': 0.8, 'relative': False},\n",
    "  'color_params': {}}}\n",
    "all_plot_params.update(cbar_params)\n",
    "all_plot_params.update(other_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dark2 colors\n",
    "set2_colors = sns.color_palette(\"Set2\")\n",
    "\n",
    "colors = {\n",
    "    'overt': set2_colors[0],\n",
    "    'mimed': set2_colors[1],\n",
    "    'alphabet1_1': set2_colors[4],\n",
    "    'alphabet1_2': set2_colors[6],\n",
    "    'hga': set2_colors[3],\n",
    "    'raw': set2_colors[2],\n",
    "    'hga + raw': set2_colors[7]\n",
    "}\n",
    "\n",
    "brain_closeup = {\n",
    "    'xlim': [200, 500],\n",
    "    'ylim': [150, 550]\n",
    "}\n",
    "\n",
    "set2_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linewidth = 1\n",
    "annot_linewidth = 1\n",
    "fontsize = 7\n",
    "plotting_defaults(font='Arial', fontsize=fontsize, linewidth=linewidth)\n",
    "panel_label_fontsize = 7\n",
    "boxplot_kwargs = {'fliersize': 3}\n",
    "scatter_size = 3\n",
    "mm = 1 / 25.4\n",
    "mm_figsize = [mm*180, mm*130]\n",
    "\n",
    "fig = plt.figure(figsize=mm_figsize)\n",
    "\n",
    "gs = mpl.gridspec.GridSpec(2, 9, figure=fig, wspace=1.5, hspace=0.6)\n",
    "sal_gs = mpl.gridspec.GridSpecFromSubplotSpec(1, 4, subplot_spec=gs[0, 3:], wspace=0.05)\n",
    "spatial_gs = mpl.gridspec.GridSpecFromSubplotSpec(1, 3, subplot_spec=gs[1, :3], wspace=0.4, hspace=0.6)\n",
    "temporal_gs = mpl.gridspec.GridSpecFromSubplotSpec(1, 3, subplot_spec=gs[1, 3:6], wspace=0.4, hspace=0.6)\n",
    "axs = {}\n",
    "\n",
    "\n",
    "##### ----- HGA vs HGA + Raw: decoding accuracies\n",
    "axs['hga_raw_accs_box'] = fig.add_subplot(gs[0, :3])\n",
    "axs['hga_raw_accs_box'] = sns.boxplot(data=hga_raw_df, x='Features', y='Accuracy', ax=axs['hga_raw_accs_box'],\n",
    "                                 order=second_feature_names.keys(), palette=[colors[key] for key in feature_names.keys()] ,\n",
    "                                     showfliers=False, **boxplot_kwargs)\n",
    "axs['hga_raw_accs_box'] = sns.stripplot(data=hga_raw_df, x='Features', y='Accuracy', ax=axs['hga_raw_accs_box'],\n",
    "                                 order=second_feature_names.keys(), palette=[colors[key] for key in feature_names.keys()], \n",
    "                                       color='black', edgecolor='black', linewidth=linewidth-0.5, size=scatter_size)\n",
    "axs['hga_raw_accs_box'].axes.set(xticklabels=second_feature_names.values(), \n",
    "                                  ylabel='NATO code-word accuracy',\n",
    "                                  ylim=(0.25, 0.6));\n",
    "axs['hga_raw_accs_box'].axes.set_xlabel('Feature type', labelpad=0)\n",
    "add_stat_annotation(axs['hga_raw_accs_box'], data=hga_raw_df, x='Features', y='Accuracy', order=second_feature_names.keys(),\n",
    "                   box_pairs=hgaraw_box_pairs, perform_stat_test=False, pvalues=hgaraw_pvals,\n",
    "                   text_format='star', loc='outside', pvalue_thresholds=pvalue_thresholds, linewidth=annot_linewidth)\n",
    "\n",
    "\n",
    "##### ----- HGA alone saliences\n",
    "axs['hga_sal_alone'] = fig.add_subplot(sal_gs[0, 0])\n",
    "all_plot_params['elec_weights'] = saliences['hga_alone_salience']\n",
    "all_plot_params['fig'] = fig\n",
    "all_plot_params['elec_size_color_params']['color_spec'] = colors['hga']\n",
    "plot_images_and_elecs(**all_plot_params, ax=axs['hga_sal_alone'])\n",
    "axs['hga_sal_alone'].axes.set(xlim=brain_closeup['xlim'], ylim=brain_closeup['ylim'], title='HGA\\nalone')\n",
    "\n",
    "\n",
    "##### ----- HGA from HGA + raw saliences\n",
    "axs['hga_sal_from_rawhga'] = fig.add_subplot(sal_gs[0, 1])\n",
    "all_plot_params['elec_weights'] = saliences['rawhga_salience'][128:]\n",
    "all_plot_params['fig'] = fig\n",
    "all_plot_params['elec_size_color_params']['color_spec'] = colors['hga']\n",
    "plot_images_and_elecs(**all_plot_params, ax=axs['hga_sal_from_rawhga'])\n",
    "axs['hga_sal_from_rawhga'].axes.set(xlim=brain_closeup['xlim'], ylim=brain_closeup['ylim'], title='HGA\\nfrom HGA+LFS')\n",
    "\n",
    "\n",
    "##### ----- Raw alone saliences\n",
    "axs['raw_sal_alone'] = fig.add_subplot(sal_gs[0, 2])\n",
    "all_plot_params['elec_weights'] = saliences['raw_alone_salience']\n",
    "all_plot_params['fig'] = fig\n",
    "all_plot_params['elec_size_color_params']['color_spec'] = colors['raw']\n",
    "plot_images_and_elecs(**all_plot_params, ax=axs['raw_sal_alone'])\n",
    "axs['raw_sal_alone'].axes.set(xlim=brain_closeup['xlim'], ylim=brain_closeup['ylim'], title='LFS\\nalone')\n",
    "\n",
    "\n",
    "##### ----- Raw from HGA + raw saliences\n",
    "axs['raw_sal_from_rawhga'] = fig.add_subplot(sal_gs[0, 3])\n",
    "ax = axs['raw_sal_from_rawhga']\n",
    "all_plot_params['elec_weights'] = saliences['rawhga_salience'][:128]\n",
    "all_plot_params['fig'] = fig\n",
    "all_plot_params['elec_size_color_params']['color_spec'] = colors['raw']\n",
    "plot_images_and_elecs(**all_plot_params, ax=axs['raw_sal_from_rawhga'])\n",
    "axs['raw_sal_from_rawhga'].axes.set(xlim=brain_closeup['xlim'], ylim=brain_closeup['ylim'], title='LFS\\nfrom HGA+LFS')\n",
    "\n",
    "\n",
    "##### ----- HGA vs HGA + Raw: Spatial PCs\n",
    "axs['alphnato_spatial_pr_stat'] = fig.add_subplot(spatial_gs[0, :3])\n",
    "axs['alphnato_spatial_pr_stat'] = sns.stripplot(data=hga_raw_pr_df, x='Condition', y='80% var PC, Spatial', ax=axs['alphnato_spatial_pr_stat'],\n",
    "                                 order=feature_names.keys(), palette=3*['white'])\n",
    "axs['alphnato_spatial_pr_stat'].axes.set(ylim=(2, 14))\n",
    "add_stat_annotation(axs['alphnato_spatial_pr_stat'], data=hga_raw_pr_df, x='Condition', y='80% var PC, Spatial', order=feature_names.keys(),\n",
    "                   box_pairs=hgaraw_pr_box_pairs['spatial'], perform_stat_test=False, pvalues=hgaraw_pr_pvals['spatial'],\n",
    "                   text_format='star', loc='outside', pvalue_thresholds=pvalue_thresholds, line_offset_to_box=0.1, linewidth=annot_linewidth)\n",
    "axs['alphnato_spatial_pr_stat'].axis('off')\n",
    "\n",
    "axs['alphnato_spatial_pr'] = [fig.add_subplot(spatial_gs[0, 0]), fig.add_subplot(spatial_gs[0, 1]), fig.add_subplot(spatial_gs[0, 2])]\n",
    "for ax, key in zip(axs['alphnato_spatial_pr'], feature_names.keys()):\n",
    "    pcs, pc_counts = np.unique(hga_raw_pr_df.loc[hga_raw_pr_df['Condition'] == key]['80% var PC, Spatial'].values, return_counts=True)\n",
    "    ax.barh(pcs, pc_counts, height=0.5, clip_on=False, color=colors[key], edgecolor='grey')\n",
    "    ax.axes.set(ylim=(4, 18), yticks=range(4, 19, 2), xlim=(0, 100), xticks=[0, 50, 100], xticklabels=[0, '', 100])\n",
    "\n",
    "axs['alphnato_spatial_pr'][0].axes.set_ylabel('No. feature PCs, $\\sigma^2$ > 80%', labelpad=-1)\n",
    "axs['alphnato_spatial_pr'][1].axes.set(xlabel='Percent of bootstraps')\n",
    "for ax in axs['alphnato_spatial_pr'][1:]:\n",
    "    ax.axes.set(yticklabels=[])\n",
    "    \n",
    "handles = []\n",
    "for key, val in feature_names.items():\n",
    "    handles.append(mpl.patches.Patch(color=colors[key], label=val))\n",
    "axs['alphnato_spatial_pr'][0].legend(handles=handles, handlelength=0.5, fontsize=fontsize-1, bbox_to_anchor=(-0.05, 0.98), loc='upper left', frameon=False)\n",
    "\n",
    "\n",
    "##### ----- HGA vs HGA + Raw: Temporal PCs\n",
    "axs['alphnato_temporal_pr_stat'] = fig.add_subplot(temporal_gs[0, :3])\n",
    "axs['alphnato_temporal_pr_stat'] = sns.stripplot(data=hga_raw_pr_df, x='Condition', y='80% var PC, Temporal', ax=axs['alphnato_temporal_pr_stat'],\n",
    "                                 order=feature_names.keys(), palette=3*['white'])\n",
    "axs['alphnato_temporal_pr_stat'].axes.set(ylim=(12, 24))\n",
    "add_stat_annotation(axs['alphnato_temporal_pr_stat'], data=hga_raw_pr_df, x='Condition', y='80% var PC, Temporal', order=feature_names.keys(),\n",
    "                   box_pairs=hgaraw_pr_box_pairs['temporal'], perform_stat_test=False, pvalues=hgaraw_pr_pvals['temporal'],\n",
    "                   text_format='star', loc='outside', pvalue_thresholds=pvalue_thresholds, line_offset_to_box=0.1, linewidth=annot_linewidth)\n",
    "axs['alphnato_temporal_pr_stat'].axis('off')\n",
    "\n",
    "axs['alphnato_temporal_pr'] = [fig.add_subplot(temporal_gs[0, 0]), fig.add_subplot(temporal_gs[0, 1]), fig.add_subplot(temporal_gs[0, 2])]\n",
    "for ax, key in zip(axs['alphnato_temporal_pr'], feature_names.keys()):\n",
    "    pcs, pc_counts = np.unique(hga_raw_pr_df.loc[hga_raw_pr_df['Condition'] == key]['80% var PC, Temporal'].values, return_counts=True)\n",
    "    \n",
    "    ax.barh(pcs, pc_counts, height=0.5, clip_on=False, color=colors[key], edgecolor='grey')\n",
    "    ax.axes.set(ylim=(12, 24), xlim=(0, 100), xticks=[0, 50, 100], xticklabels=[0, '', 100])\n",
    "\n",
    "axs['alphnato_temporal_pr'][0].axes.set_ylabel('No. temporal PCs, $\\sigma^2$ > 80%', labelpad=-1)\n",
    "axs['alphnato_temporal_pr'][1].axes.set(xlabel='Percent of bootstraps')\n",
    "for ax in axs['alphnato_temporal_pr'][1:]:\n",
    "    ax.axes.set(yticklabels=[])\n",
    "    \n",
    "handles = []\n",
    "for key, val in feature_names.items():\n",
    "    handles.append(mpl.patches.Patch(color=colors[key], label=val))\n",
    "axs['alphnato_temporal_pr'][0].legend(handles=handles, handlelength=0.5, fontsize=fontsize-1, bbox_to_anchor=(-0.05, 0.98), loc='upper left', frameon=False)\n",
    "\n",
    "\n",
    "##### ----- Temporal smoothing\n",
    "axs['temporal_smoothing'] = fig.add_subplot(gs[1, 6:])\n",
    "axs['temporal_smoothing'] = sns.lineplot(data=temporal_smoothing, x='Temporal Smoothing (s)', y='accuracy (% of original)', hue='Data Type',\n",
    "             ax=axs['temporal_smoothing'], hue_order=['hga', 'raw', 'hga_and_raw'], ci=99, err_style='bars',\n",
    "              palette=[colors['hga'], colors['raw'], colors['hga + raw']], estimator=np.median, clip_on=False)\n",
    "axs['temporal_smoothing'] = sns.scatterplot(data=temporal_smoothing.groupby(['Temporal Smoothing (s)', 'Data Type']).median(), x='Temporal Smoothing (s)', \n",
    "                                            y='accuracy (% of original)', hue='Data Type', clip_on=False,\n",
    "                 ax=axs['temporal_smoothing'], hue_order=['hga', 'raw', 'hga_and_raw'], s=25, legend=False,\n",
    "                  palette=[colors['hga'], colors['raw'], colors['hga + raw']])\n",
    "\n",
    "plt.setp(axs['temporal_smoothing'].lines, clip_on=False)\n",
    "axs['temporal_smoothing'].axes.set(ylim=(0.2, 1.0),\n",
    "                                   xlabel='Gaussian filter width (s)', xlim=(None, 1.0))\n",
    "axs['temporal_smoothing'].axes.set_ylabel('Fraction of original accuracy', labelpad=0)\n",
    "handles, labels = axs['temporal_smoothing'].get_legend_handles_labels()\n",
    "axs['temporal_smoothing'].legend(handles=handles, labels=[all_feature_names[key] for key in labels], \n",
    "                                 frameon=False, bbox_to_anchor=(1, 0.98), loc='upper right', fontsize=fontsize-1);\n",
    "for o in plt.findobj():\n",
    "    o.set_clip_on(False)\n",
    "    \n",
    "fig.tight_layout();\n",
    "\n",
    "##### ----- Figure panel labels\n",
    "axs['hga_raw_accs_box'].annotate('a', (-0.2, 1.09), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['hga_sal_alone'].annotate('b', (-0.03, 1.27), xycoords='axes fraction', ha='left', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['hga_sal_from_rawhga'].annotate('c', (-0.03, 1.27), xycoords='axes fraction', ha='left', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['raw_sal_alone'].annotate('d', (-0.03, 1.27), xycoords='axes fraction', ha='left', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['raw_sal_from_rawhga'].annotate('e', (-0.03, 1.27), xycoords='axes fraction', ha='left', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['alphnato_spatial_pr_stat'].annotate('f', (-0.1, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['alphnato_temporal_pr_stat'].annotate('g', (-0.1, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold')\n",
    "axs['temporal_smoothing'].annotate('h', (-0.1, 1.1), xycoords='axes fraction', ha='right', fontsize=panel_label_fontsize, weight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_dpi = 300\n",
    "\n",
    "for ext in ['png', 'pdf']:\n",
    "    fig.savefig(os.path.join(fig_dir, f'figure3_hga_vs_raw.{ext}'), \n",
    "                transparent=True, bbox_inches='tight', dpi=figure_dpi)\n",
    "    fig.savefig(os.path.join(fig_dir, f'figure3_hga_vs_raw_white.{ext}'), \n",
    "                transparent=False, bbox_inches='tight', dpi=figure_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gentz",
   "language": "python",
   "name": "gentz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
