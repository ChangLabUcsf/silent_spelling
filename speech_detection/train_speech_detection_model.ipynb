{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant code and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native Python packages\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Third party libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Custom code\n",
    "from data import data as data_class\n",
    "from rnn_speech_detection import PyTorchEventDetector\n",
    "from torch_model import speech_detector as lstm_model\n",
    "from utils import FLAGS as FLAGS_class, load_parameters_and_directories, update_parameters_and_flags, \\\n",
    "    universal_parser, update_dependent_parameters, write_model_description_json, logger_config\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "mpl.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the path of this repo\n",
    "Set this path to correspond to where you've placed the repo. Directly inside this path should be the `data`, `results`, model configuation, and this notebook (`train_speech_detection_model.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = '/path/to/silent_spelling/speech_detection/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters relevant to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse command line arguments.\n",
    "parser = universal_parser()\n",
    "pargs = parser.parse_args(args=[])\n",
    "\n",
    "# The paradigms corresponding to each of the utterance sets, in order\n",
    "pargs.paradigms = '[\"mimed\",\"mimed\",\"mimed\",\"attempted_motor\"]'\n",
    "\n",
    "# The utterance sets included in the training data\n",
    "pargs.utterance_sets = '[\"alphabet1_2_with_right_v2\",\"alphabet1_2_with_right\",\"alphabet1_2\",\"navigation1\"]'\n",
    "\n",
    "# Where results (and trained models) will be saved\n",
    "pargs.out_folder = 'results'\n",
    "\n",
    "# The order of the labels\n",
    "pargs.feature_labels = '[\"silence\",\"speech\",\"preparation\",\"motor\"]'#,\"garbage1\",\"garbage2\",\"garbage4\"]'\n",
    "pargs.total_feature_labels = pargs.feature_labels\n",
    "\n",
    "# The name of the prediction fold. This is a key in the block splits file and\n",
    "# defining this tells the model which training split to use.\n",
    "pargs.prediction_fold = 'demo'\n",
    "\n",
    "# Name of the project if tracking in wandb\n",
    "pargs.project_name = 'demo'  \n",
    "\n",
    "# Number of blocks to pull from each utterance set for the validation set\n",
    "pargs.num_val_blocks = 1\n",
    "\n",
    "# Set the training flag to True and indicate\n",
    "# the prespecified fold splits are being used.\n",
    "pargs.do_training = True\n",
    "pargs.prediction_folds = True\n",
    "\n",
    "# The prefix of the model configuration. This allows\n",
    "# you to define multiple configurations and specify \n",
    "# which to use flexibly.\n",
    "pargs.config_prefix = 'demo_'\n",
    "\n",
    "# The subject ID\n",
    "pargs.subject = 'bravo1'\n",
    "\n",
    "# Filename of the block splits\n",
    "pargs.block_split_filename = 'demo_block_splits.pkl'\n",
    "\n",
    "# Name of the folder containing the prepared data\n",
    "pargs.prepared_data_folder_name = 'data'\n",
    "\n",
    "# Model run: if you wish to save more than 1 run of the same model,\n",
    "# increase this number\n",
    "pargs.run = 0\n",
    "\n",
    "# Model version\n",
    "pargs.model_version = 'torch'\n",
    "\n",
    "# The value of the false positive weight, as defined \n",
    "# in the Supplement of the paper\n",
    "pargs.false_positive_weight = 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set other flags relevant to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set flags\n",
    "FLAGS = FLAGS_class()\n",
    "FLAGS.do_inference = pargs.do_inference\n",
    "FLAGS.do_training = pargs.do_training\n",
    "FLAGS.get_saliences = pargs.get_saliences\n",
    "FLAGS.prediction_folds = pargs.prediction_folds\n",
    "FLAGS.create_predictions = pargs.create_predictions\n",
    "FLAGS.use_presaved_inference_blocks = pargs.use_presaved_inference_blocks\n",
    "FLAGS.process_and_save_only = pargs.process_and_save_only\n",
    "FLAGS.kfold_cross_validation = False\n",
    "FLAGS.train_master_model = False\n",
    "FLAGS.store_weights = True\n",
    "FLAGS.save_logits = False\n",
    "FLAGS.do_hyperopt = False\n",
    "FLAGS.use_hyperopted_params = pargs.use_hyperopted_params\n",
    "FLAGS.no_early_stopping_learning_rate_adjustment = pargs.no_early_stopping_learning_rate_adjustment\n",
    "\n",
    "# Initialize the logger\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(**logger_config)\n",
    "logger = logging.getLogger('speech_detection')\n",
    "\n",
    "# Load the parameters object based on the model configuration JSON.\n",
    "# Update it with the parsed arguments. Load directory information\n",
    "params, dirs = load_parameters_and_directories(\n",
    "    model_type=f'supervised_lstm_model',\n",
    "    config_path=repo_path,\n",
    "    pargs=pargs,\n",
    "    config_prefix='demo_'\n",
    ")\n",
    "\n",
    "# Update the FLAGS and params based on the FLAGS.\n",
    "params, FLAGS = update_parameters_and_flags(params, FLAGS, pargs=pargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the specific directories.\n",
    "# dirs.data = repo_path + 'data'\n",
    "dirs.prepared_data_dir = repo_path + 'bravo1/data'  # where the prepared data is\n",
    "dirs.general_output_dir = repo_path  # where to get general files\n",
    "dirs.output = repo_path + 'bravo1/results'  # Where to save models\n",
    "\n",
    "if not os.path.exists(dirs.output):\n",
    "    os.makedirs(dirs.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load prepared data and split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(repo_path + 'block_breakdowns.json', 'r') as f:\n",
    "    full_block_breakdowns = json.load(f)\n",
    "    block_breakdown = full_block_breakdowns[params.subject_id]\n",
    "\n",
    "params.num_folds = 1\n",
    "params.rt_class = None\n",
    "prefixes = [\n",
    "    'window{:03d}_fold{}'.format(params.int_window, cur_fold)\n",
    "    for cur_fold in range(params.num_folds)\n",
    "]\n",
    "cur_model_run = pargs.run\n",
    "dirs.fold_output_models = [\n",
    "    os.path.join(dirs.output,\n",
    "            '{}_model_run{}'.format(cur_prefix, cur_model_run))\n",
    "    for cur_prefix in prefixes\n",
    "]\n",
    "\n",
    "# Get blocks and load data.\n",
    "data = data_class(repo_path + 'log.log')\n",
    "data._get_blocks(FLAGS=FLAGS, dirs=dirs, params=params, args=pargs)\n",
    "\n",
    "ifold = 0\n",
    "fold_start = time.time()\n",
    "\n",
    "# Define more specific paths for where to save and load the models.\n",
    "prefix = prefixes[ifold]\n",
    "dirs.fold_output_model = dirs.fold_output_models[ifold]\n",
    "\n",
    "# We're only going to load the validation data, we'll load\n",
    "# training data on the fly for each epoch\n",
    "data.load_prepared_data(FLAGS=FLAGS, params=params, fold=ifold,\n",
    "                        block_breakdown=full_block_breakdowns,\n",
    "                        data_dir=dirs.prepared_data_dir)\n",
    "\n",
    "try:\n",
    "    os.mkdir(dirs.fold_output_model)\n",
    "except FileExistsError:\n",
    "    logger.info('Model folder already exists.')\n",
    "\n",
    "# Save all model configurations to the output model folder.\n",
    "write_model_description_json(params,\n",
    "                             data.blocks_for_training,\n",
    "                             data.blocks_for_validation,\n",
    "                             dirs.fold_output_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a speech detection model with the demo data\n",
    "\n",
    "If you wish to use a GPU for training, set `device = 'cuda'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elapsed time for each training loop will print and be saved to the logger.\n",
    "\n",
    "Estimated training times for the example dataset:\n",
    "* Using a Tesla V100 GPU and Linux server using Ubuntu 20.04, each epoch (including data loading and minibatch updates) takes ~ 1 minute.\n",
    "* Using only CPUs on a Linux server using Ubuntu 20.04, each epoch (including data loading and minibatch updates) takes ~ 3.5 minutes.\n",
    "* Using only CPUs on a MacBook Pro (macOS 10.15.7), each epoch (including data loading and minibatch updates) takes ~ 2.5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the speech detection model.\n",
    "# If you have a wandb account, this will enable tracking training/validation \n",
    "# losses and accuracies under the project name specified at the top of the notebook\n",
    "speech_detection_model = lstm_model(params, FLAGS, 'log.log', use_wandb=False, device=device)  \n",
    "\n",
    "# Train a new model.\n",
    "logger.info(\n",
    "    'Model and outputs saved to : {}'.format(dirs.output))\n",
    "logger.info('Data fold preparation time: {0:.3f} s'.format(\n",
    "    time.time() - fold_start))\n",
    "logger.info('Fold {} training blocks: {}'.format(\n",
    "    ifold, data.blocks_for_training))\n",
    "logger.info('Fold {} validation blocks: {}'.format(\n",
    "    ifold, data.blocks_for_validation))\n",
    "logger.info('neural val data shape')\n",
    "logger.info([b.shape for b in data.neural_val])\n",
    "logger.info('events val data shape')\n",
    "logger.info([b.shape for b in data.events_val])\n",
    "logger.info('*************************************')\n",
    "\n",
    "train_start = time.time()\n",
    "\n",
    "# Train the model.\n",
    "speech_detection_model.train(\n",
    "    data.trial_map,\n",
    "    data.neural_val,\n",
    "    data.events_val,\n",
    "    output_dir=dirs.output,\n",
    "    output_model_dir=dirs.fold_output_model,\n",
    "    model_tracking=True,\n",
    "    shuffle_batch=True,\n",
    "    data_dir=dirs.prepared_data_dir,\n",
    "    training_blocks=data.blocks_for_training,\n",
    "    validation_blocks=data.blocks_for_validation\n",
    ")\n",
    "\n",
    "logger.info('Done training!')\n",
    "logger.info('Total training time: {0:.3f} s'.format(\n",
    "    time.time() - train_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a pre-trained speech detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pretrained model that used more data\n",
    "model_path = repo_path + 'pretrained_example_model'\n",
    "\n",
    "## Load the model you just trained\n",
    "# model_path = repo_path + 'bravo1/results/window100_fold0_model_run0'\n",
    "\n",
    "# Initialize the model and load the function to predict silent speech probabilities from ECoG data\n",
    "model = PyTorchEventDetector(restore_path=model_path, testing=True)\n",
    "model.build(device='cpu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example block of data\n",
    "with open(repo_path + 'bravo1/data/2726-conv.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    ecog = data['ecog']\n",
    "    events = data['events']\n",
    "    sr = data['sr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model to predict speech probabilities from a sentence-spelling block\n",
    "\n",
    "In each trial of the sentence-spelling block, the participant uses silent-speech attempts to spell out the intended message.\n",
    "At the end of the trial, the participant attempts to make a hand movement to finalize the sentence before proceeding to the next trial.\n",
    "Therefore, the detected probabilities should show `speech` activity throughout the majority of each trial and `motor` activity at the end of each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to a tensor and use the pre\n",
    "block_tensor = torch.tensor(ecog, dtype=torch.float32).unsqueeze(0).to('cpu')\n",
    "probs = []\n",
    "with torch.no_grad():\n",
    "    for m in model.models:\n",
    "        probs.append(m(block_tensor))\n",
    "stack_probs = torch.stack(probs, dim=0).cpu().numpy()\n",
    "probs = np.mean(stack_probs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "target_pres = events.loc[(events['phase_num'] == 1) & (events['state_num'] == 2)]['elapsed_time'].values\n",
    "for i, cue in enumerate(target_pres):\n",
    "    if i == 0:\n",
    "        ax.axvline(x=cue, linestyle='--', alpha=0.6, color='g', label='trial start')\n",
    "    else:\n",
    "        ax.axvline(x=cue, linestyle='--', alpha=0.6, color='g')\n",
    "    \n",
    "trial_end = events.loc[(events['phase_num'] == 3) & (events['state_num'] == 2)]['elapsed_time'].values\n",
    "for i, cue in enumerate(trial_end):\n",
    "    if i == 0:\n",
    "        ax.axvline(x=cue, linestyle='--', alpha=0.6, color='r', label='trial end')\n",
    "    else:\n",
    "        ax.axvline(x=cue, linestyle='--', alpha=0.6, color='r')\n",
    "\n",
    "x = np.arange(probs.shape[0]) / sr\n",
    "for cur_event, event_type in enumerate(model.event_mapping):\n",
    "    ax.plot(x, cur_event + probs[:, cur_event])\n",
    "\n",
    "ax.axes.set(xlabel='Time (s)', yticks=0.5 + np.arange(0, 4), yticklabels=model.event_mapping)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1.01));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
